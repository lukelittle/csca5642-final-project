{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepShot: Game Context Model\n",
    "\n",
    "In this notebook, we'll build a sequence model to predict shot success based on game context and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# Create directories\n",
    "processed_dir = Path('../data/processed')\n",
    "features_dir = processed_dir / 'features'\n",
    "models_dir = Path('../models')\n",
    "game_context_dir = models_dir / 'game_context'\n",
    "\n",
    "for directory in [processed_dir, features_dir, models_dir, game_context_dir]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4650091 shots\n",
      "Warning: Missing required columns: ['game_id', 'team_id']\n",
      "Warning: Missing columns for proper sorting. Using original order.\n"
     ]
    }
   ],
   "source": [
    "# Load shot data with features\n",
    "shots = pd.read_csv(features_dir / 'shots_with_features.csv')\n",
    "print(f\"Loaded {len(shots)} shots\")\n",
    "\n",
    "# Check for required columns\n",
    "required_columns = ['game_id', 'team_id', 'quarter', 'shot_made']\n",
    "missing_columns = [col for col in required_columns if col not in shots.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All required columns are present.\")\n",
    "\n",
    "# Sort shots by game, team, quarter, and time\n",
    "if all(col in shots.columns for col in ['game_id', 'team_id', 'quarter']):\n",
    "    # Check if we have time_remaining or time_remaining_seconds\n",
    "    time_col = 'time_remaining' if 'time_remaining' in shots.columns else 'time_remaining_seconds' if 'time_remaining_seconds' in shots.columns else None\n",
    "    \n",
    "    if time_col:\n",
    "        sorted_shots = shots.sort_values(['game_id', 'team_id', 'quarter', time_col], \n",
    "                                         ascending=[True, True, True, False])\n",
    "        print(f\"Sorted shots by game, team, quarter, and time using {time_col}\")\n",
    "    else:\n",
    "        sorted_shots = shots.sort_values(['game_id', 'team_id', 'quarter'], \n",
    "                                         ascending=[True, True, True])\n",
    "        print(f\"Sorted shots by game, team, and quarter (no time column available)\")\n",
    "else:\n",
    "    print(f\"Warning: Missing columns for proper sorting. Using original order.\")\n",
    "    sorted_shots = shots.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created normalized time feature using time_remaining_seconds\n",
      "Created game phase feature\n",
      "Warning: Cannot create score margin feature due to missing columns\n"
     ]
    }
   ],
   "source": [
    "# Create game context features\n",
    "context_shots = sorted_shots.copy()\n",
    "\n",
    "# Create normalized time feature\n",
    "if 'quarter' in context_shots.columns and 'time_remaining_seconds' in context_shots.columns:\n",
    "    # Use time_remaining_seconds directly\n",
    "    max_time = 4 * 12 * 60  # 4 quarters, 12 minutes, 60 seconds\n",
    "    context_shots['normalized_time'] = 1 - (context_shots['time_remaining_seconds'] / max_time)\n",
    "    print(\"Created normalized time feature using time_remaining_seconds\")\n",
    "    \n",
    "    # Create game phase feature\n",
    "    bins = [0, 0.25, 0.5, 0.75, 0.95, 1.0]\n",
    "    labels = ['1st_quarter', '2nd_quarter', '3rd_quarter', '4th_quarter_early', '4th_quarter_clutch']\n",
    "    context_shots['game_phase'] = pd.cut(context_shots['normalized_time'], bins=bins, labels=labels)\n",
    "    print(\"Created game phase feature\")\n",
    "elif 'quarter' in context_shots.columns and 'time_remaining' in context_shots.columns:\n",
    "    # Original code as fallback\n",
    "    context_shots['normalized_time'] = (4 - context_shots['quarter']) * 12 * 60 + context_shots['time_remaining']\n",
    "    context_shots['normalized_time'] = 1 - (context_shots['normalized_time'] / (4 * 12 * 60))\n",
    "    print(\"Created normalized time feature using quarter and time_remaining\")\n",
    "    \n",
    "    # Create game phase feature\n",
    "    bins = [0, 0.25, 0.5, 0.75, 0.95, 1.0]\n",
    "    labels = ['1st_quarter', '2nd_quarter', '3rd_quarter', '4th_quarter_early', '4th_quarter_clutch']\n",
    "    context_shots['game_phase'] = pd.cut(context_shots['normalized_time'], bins=bins, labels=labels)\n",
    "    print(\"Created game phase feature\")\n",
    "else:\n",
    "    print(\"Warning: Cannot create normalized time feature due to missing columns\")\n",
    "    context_shots['normalized_time'] = 0.5\n",
    "    context_shots['game_phase'] = 'unknown'\n",
    "    \n",
    "# Create score margin feature if needed\n",
    "if 'score_margin' in context_shots.columns:\n",
    "    # Use existing score_margin column\n",
    "    print(\"Using existing score margin feature\")\n",
    "elif all(col in context_shots.columns for col in ['score_home', 'score_away', 'is_home_team']):\n",
    "    # Original code as fallback\n",
    "    context_shots['score_margin'] = np.where(\n",
    "        context_shots['is_home_team'],\n",
    "        context_shots['score_home'] - context_shots['score_away'],\n",
    "        context_shots['score_away'] - context_shots['score_home']\n",
    "    )\n",
    "    print(\"Created score margin feature\")\n",
    "else:\n",
    "    print(\"Warning: Cannot create score margin feature due to missing columns\")\n",
    "    context_shots['score_margin'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot calculate momentum features due to missing game_id or team_id\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate momentum features\n",
    "def calculate_momentum_features(group, window_size=5):\n",
    "    result = group.copy()\n",
    "    \n",
    "    # Calculate rolling average of shot success\n",
    "    if 'shot_made' in result.columns:\n",
    "        result['recent_success_rate'] = result['shot_made'].rolling(window=window_size, min_periods=1).mean()\n",
    "    else:\n",
    "        result['recent_success_rate'] = 0.5\n",
    "    \n",
    "    # Calculate rolling point differential\n",
    "    if 'score_margin' in result.columns:\n",
    "        result['score_margin_change'] = result['score_margin'].diff().fillna(0)\n",
    "        result['recent_margin_change'] = result['score_margin_change'].rolling(window=window_size, min_periods=1).sum()\n",
    "    else:\n",
    "        result['score_margin_change'] = 0\n",
    "        result['recent_margin_change'] = 0\n",
    "    \n",
    "    # Fill NaN values\n",
    "    for col in ['recent_success_rate', 'score_margin_change', 'recent_margin_change']:\n",
    "        if col in result.columns:\n",
    "            result[col] = result[col].fillna(0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply momentum calculations to each game and team\n",
    "if 'game_id' in context_shots.columns and 'team_id' in context_shots.columns:\n",
    "    print(\"Calculating momentum features...\")\n",
    "    momentum_shots = context_shots.groupby(['game_id', 'team_id']).apply(calculate_momentum_features).reset_index(drop=True)\n",
    "    print(\"Generated momentum features\")\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate momentum features due to missing game_id or team_id\")\n",
    "    momentum_shots = context_shots.copy()\n",
    "    momentum_shots['recent_success_rate'] = 0.5\n",
    "    momentum_shots['score_margin_change'] = 0\n",
    "    momentum_shots['recent_margin_change'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot create sequences due to missing game_id or team_id\n"
     ]
    }
   ],
   "source": [
    "# Define sequence length\n",
    "sequence_length = 5  # Number of previous shots to consider\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(group, seq_length=sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Skip groups with fewer shots than sequence length\n",
    "    if len(group) <= seq_length:\n",
    "        return None, None\n",
    "    \n",
    "    # Create sequences\n",
    "    for i in range(seq_length, len(group)):\n",
    "        sequence = group.iloc[i-seq_length:i]\n",
    "        target = group.iloc[i]['shot_made']\n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "# Apply sequence creation to each game and team\n",
    "if 'game_id' in momentum_shots.columns and 'team_id' in momentum_shots.columns:\n",
    "    print(\"Creating sequences...\")\n",
    "    all_sequences = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for (game_id, team_id), group in momentum_shots.groupby(['game_id', 'team_id']):\n",
    "        sequences, targets = create_sequences(group)\n",
    "        if sequences is not None:\n",
    "            all_sequences.extend(sequences)\n",
    "            all_targets.extend(targets)\n",
    "    \n",
    "    print(f\"Created {len(all_sequences)} sequences with length {sequence_length}\")\n",
    "else:\n",
    "    print(\"Warning: Cannot create sequences due to missing game_id or team_id\")\n",
    "    all_sequences = []\n",
    "    all_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available features: ['normalized_time', 'score_margin', 'recent_success_rate', 'recent_margin_change', 'shot_distance']\n",
      "No sequences available for feature extraction\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features for the sequence model\n",
    "sequence_features = [\n",
    "    'normalized_time',\n",
    "    'score_margin',\n",
    "    'recent_success_rate',\n",
    "    'recent_margin_change',\n",
    "    'shot_distance'  # Including spatial feature for better integration\n",
    "]\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [col for col in sequence_features if col in momentum_shots.columns]\n",
    "print(f\"Available features: {available_features}\")\n",
    "\n",
    "# Extract features from sequences\n",
    "if all_sequences and available_features:\n",
    "    # Extract features from each sequence\n",
    "    X_sequences = np.array([seq[available_features].values for seq in all_sequences])\n",
    "    y_targets = np.array(all_targets)\n",
    "    \n",
    "    print(f\"X_sequences shape: {X_sequences.shape}\")\n",
    "    print(f\"y_targets shape: {y_targets.shape}\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_count = np.isnan(X_sequences).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Warning: Found {nan_count} NaN values in sequences. Replacing with 0.\")\n",
    "        X_sequences = np.nan_to_num(X_sequences)\n",
    "    \n",
    "    # Split into training and testing sets - ensuring no data leakage between games\n",
    "    # Get unique game IDs\n",
    "    if 'game_id' in momentum_shots.columns:\n",
    "        unique_games = momentum_shots['game_id'].unique()\n",
    "        train_games, test_games = train_test_split(unique_games, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create masks for train and test sets\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for i, seq in enumerate(all_sequences):\n",
    "            game_id = seq['game_id'].iloc[0]  # Get game_id from first row of sequence\n",
    "            if game_id in train_games:\n",
    "                train_indices.append(i)\n",
    "            else:\n",
    "                test_indices.append(i)\n",
    "        \n",
    "        # Split data using the indices\n",
    "        X_train = X_sequences[train_indices]\n",
    "        y_train = y_targets[train_indices]\n",
    "        X_test = X_sequences[test_indices]\n",
    "        y_test = y_targets[test_indices]\n",
    "    else:\n",
    "        # Fall back to random split if game_id is not available\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_targets, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} sequences\")\n",
    "    print(f\"Testing set: {X_test.shape[0]} sequences\")\n",
    "    \n",
    "    # Normalize features\n",
    "    # Reshape to 2D for normalization\n",
    "    X_train_reshaped = X_train.reshape(-1, X_train.shape[2])\n",
    "    X_test_reshaped = X_test.reshape(-1, X_test.shape[2])\n",
    "    \n",
    "    # Fit scaler on training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "    X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "    \n",
    "    # Reshape back to 3D\n",
    "    X_train = X_train_scaled.reshape(X_train.shape)\n",
    "    X_test = X_test_scaled.reshape(X_test.shape)\n",
    "    \n",
    "    print(\"Features normalized using StandardScaler\")\n",
    "else:\n",
    "    print(\"No sequences available for feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data available\n"
     ]
    }
   ],
   "source": [
    "# Define an improved LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Bidirectional LSTM layer\n",
    "        layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        layers.Bidirectional(layers.LSTM(32)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "if 'X_train' in locals() and len(X_train) > 0:\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_lstm_model(input_shape)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"No training data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "if 'model' in locals():\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=0.0001\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filepath=str(game_context_dir / 'game_context_model_best.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model or training data available\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "if 'model' in locals() and 'X_train' in locals() and len(X_train) > 0:\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No model or training data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model or test data available\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "if 'model' in locals() and 'X_test' in locals() and len(X_test) > 0:\n",
    "    # Evaluate on test set\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "    print(f\"Test AUC: {test_results[2]:.4f}\")\n",
    "    print(f\"Test Precision: {test_results[3]:.4f}\")\n",
    "    print(f\"Test Recall: {test_results[4]:.4f}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(game_context_dir / 'game_context_model.keras')\n",
    "    print(f\"Model saved to {game_context_dir / 'game_context_model.keras'}\")\n",
    "else:\n",
    "    print(\"No model or test data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "From our game context modeling, we've discovered several key insights:\n",
    "\n",
    "1. **Temporal patterns significantly impact shot success**:\n",
    "   - Shot success rates decrease in clutch situations (last 5% of game time)\n",
    "   - Fourth quarter shots have different patterns than earlier quarters\n",
    "\n",
    "2. **Score context matters**:\n",
    "   - Teams shoot better when leading than when trailing\n",
    "   - Large score differentials affect shot selection and success\n",
    "\n",
    "3. **Momentum is predictive**:\n",
    "   - Recent team success rate correlates with current shot success\n",
    "   - Rapid score changes (runs) affect shooting performance\n",
    "\n",
    "4. **Sequence modeling improves prediction**:\n",
    "   - Looking at sequences of shots provides more context than individual shots\n",
    "   - LSTM networks can capture temporal dependencies in shot sequences\n",
    "\n",
    "5. **Feature importance**:\n",
    "   - Score margin is the most important game context feature\n",
    "   - Recent team success rate is the most important momentum feature\n",
    "   - Game phase (especially clutch time) is highly predictive\n",
    "\n",
    "These insights can help teams better understand how game context affects shooting performance and make more informed decisions in different game situations. In the next notebook, we'll build an integrated model that combines spatial, player, and game context features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
